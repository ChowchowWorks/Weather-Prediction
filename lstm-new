import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split , cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error
import optuna
import xgboost as xgb
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
import keras
from keras import Model
from keras import Sequential

class MyModel(Model):
     def __init__(self, nn, input_shape):
        super().__init__()
        self.model = Sequential()

        # Copy all layers except the last (Dense) layer
        for layer in nn.model.layers[:-1]:
            new_layer = layer.__class__.from_config(layer.get_config())  # Clone layer structure
            self.model.add(new_layer)  # Add to new model

        # Build the model with a dummy input to initialize weights
        dummy_input = np.zeros(input_shape)  # Shape: (batch_size=1, timesteps, features)
        _ = self.model(dummy_input)

        # Copy weights after the model has been built
        for new_layer, old_layer in zip(self.model.layers, nn.model.layers[:-1]):
            new_layer.set_weights(old_layer.get_weights())

df = pd.read_csv('weather_data.csv')

# removes outliers from humidity column only
def removeOutliers(dataframe):
  dataframe = dataframe[dataframe['relative_humidity'] <= 1]
  return dataframe

# splits the data into X values and Y values (returns arrays)
def splitDataIntoArray(data):
  if isinstance(data, pd.DataFrame):
    data = data.to_numpy()
  X = data[:, :-1]
  y = data[:, -1]
  return X, y

# creating windows for prediction
def create_windows(data, n_steps, forecast_steps):
    X, y = [], []
    for i in range(n_steps, len(data) - forecast_steps):
        X.append(data[i - n_steps:i, :-1])  # Use N previous time points as features
        y.append(data[i + forecast_steps - 1, -1])  # Predict target after forecast_steps
    return np.array(X), np.array(y)

# this is the standardisation scaler
scaler = StandardScaler()

# split data into X values and y values
X, y = splitDataIntoArray(df)
# split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)
print(X_train.shape)

# standardise X_train
X_train = np.array(scaler.fit_transform(X_train))
#X_train = np.hstack((X_train, Day_or_Night[:X_train.shape[0]]))
# standardise X_test
X_test = np.array(scaler.transform(X_test))
#X_test = np.hstack((X_test, Day_or_Night[X_train.shape[0]:]))

# create windows for training data
# N is the number of steps the model will backtrack to predict new data
N = 24

# combine X_train and y_train
y_train = y_train.reshape(y_train.shape[0], 1)
trainingData = np.hstack((X_train, y_train))

# create training data
X_train_1, y_train_1 = create_windows(trainingData, N, 1)
X_train_6, y_train_6 = create_windows(trainingData, N, 6)
X_train_24, y_train_24 = create_windows(trainingData, N, 24)

# create windows for testing data
# combine X_test and y_test
y_test = y_test.reshape(y_test.shape[0], 1)
testingData = np.hstack((X_test, y_test))

X_test_1, y_test_1 = create_windows(testingData, N, 1)
X_test_6, y_test_6 = create_windows(testingData, N, 6)
X_test_24, y_test_24 = create_windows(testingData, N, 24)

keras.utils.get_custom_objects()['MyModel'] = MyModel

lstm_1hr = keras.models.load_model('lstm-xgb-lstm_1hr.h5', compile= False)
lstm_6hr = keras.models.load_model('lstm-xgb-lstm_6hr.h5', compile = False)
lstm_24hr = keras.models.load_model('lstm-xgb-lstm_24hr.h5', compile = False)



feature_matrix_1 = lstm_1hr.predict(X_test_1)
feaure_matrix_6 = lstm_1hr.predict(X_test_6)
feature_matrix_24= lstm_1hr.predict(X_test_24)

xgb_1hr = xgb.Booster()
xgb_6hr = xgb.Booster()
xgb_24hr = xgb.Booster()

xgb_1hr.load_model("lstm-xgb-xgb_1hr.model")
xgb_6hr.load_model("lstm-xgb-xgb_6hr.model")
xgb_24hr.load_model("lstm-xgb-xgb_24hr.model")

predictions_1hr, mae_1hr, mse_1hr, rmse_1hr = xgb_1hr.predict(feature_matrix_1, y_test_1)
predictions_6hr, mae_6hr, mse_6hr, rmse_6hr = xgb_6hr.predict(feaure_matrix_6, y_test_6)
predictions_24hr, mae_24hr, mse_24hr, rmse_24hr = xgb_24hr.predict(feature_matrix_24, y_test_24)

def plot_predictions_vs_actual(predictions, actual, task_name):
    plt.figure(figsize=(10, 6))
    plt.plot(actual, label='Actual', color='blue')
    plt.plot(predictions, label='Predicted', color='red', linestyle='--')
    plt.title(f'Predictions vs Actual for {task_name} - XGBoost')
    plt.xlabel('Time')
    plt.ylabel('Relative Humidity')
    plt.legend()
    plt.tight_layout()
    plt.savefig(f'{task_name}_predictions_vs_actual_XGBoost.png')
    plt.show()
    plt.close()

plot_predictions_vs_actual(predictions_1hr, y_test_1, "1 Hour")
plot_predictions_vs_actual(predictions_6hr, y_test_6, "6 Hours")
plot_predictions_vs_actual(predictions_24hr, y_test_24, "24 Hours")

# Evaluate performance metrics
metrics_df = pd.DataFrame(
    [[mae_1hr, mse_1hr, rmse_1hr], [mae_6hr, mse_6hr, rmse_6hr], [mae_24hr, mse_24hr, rmse_24hr]],
    columns=['MAE', 'MSE', 'RMSE'],
    index=['1 Hour', '6 Hours', '24 Hours'])


residuals_1hr = y_test_1 - predictions_1hr
residuals_6hr = y_test_6 - predictions_6hr
residuals_24hr = y_test_24 - predictions_24hr

plt.hist(residuals_1hr, bins= 45)
plt.title("Histogram of Residuals")
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.show()
plt.close()
plt.hist(residuals_6hr, bins = 45)
plt.title("Histogram of Residuals")
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.show()
plt.close()
plt.hist(residuals_24hr, bins = 45)
plt.title("Histogram of Residuals")
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.show()
plt.close()